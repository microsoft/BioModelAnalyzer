# NLParser Documentation

This NLParser is developed using the Chevrotain JavaScript DSL parsing library. The aim of the NLParser is to take as input a JSON representation of the BMA model and an LTL query in natural language to generate a syntactically and semantically correct LTL query that can be consumed by the front end of BMA. 

The parsing routine is split into the following core phases:

- Preprocessing
- Lexing
- Parsing 
- Postprocessing

We first describe the grammar that is used in our parser and then move onto describing each of the phases

## Grammar

The following is the grammar for our language:

formula
    : (unaryoperators)* conditionalsExpression (unaryoperators)* | (unaryoperators)* disjunctionExpression (unaryoperators)*

conditionalsExpression
    : "If" disjunctionExpression "Then" disjunctionExpression

disjunctionExpression
    : conjunctionExpression ("Or" conjunctionExpression)*

conjunctionExpression
    : temporalExpression ("And" temporalExpression)*

temporalExpression
    : atomicExpression (binaryTemporalOperators atomicExpression)*

atomicExpression
    : (unaryoperators)* activityExpression | (unaryoperators)* relationalExpression | (unaryoperators)* FormulaPointerToken | (unaryoperators)* booleanLiteral | (unaryoperators)* developmentalEndState

activityExpression
    : ModelVariable (=)? activityClass

relationalExpression
    : ModelVariable relationalOperator IntegerLiteral

booleanLiteral
    :  "true" | "false"

developmentalEndState
    :   SelfLoop | Oscillation

binaryTemporalOperators
    : "until" | "weak until" | "release" | "upto"

activityClass
    : Active | InActive | MaximumActivity | MinimumActivity | HighActivity | LowActivity

relationalOperator
    : ">" | "<" | ">=" | "=" | "<=" | "!="

unaryOperator
    : "not" | "next" | "always" | "eventually" | "then"

### Operator Precedence

- unary operators have the highest precedence
- binary temporal operators have higher precedence than binary logical operators
- conjunction has greater precedence than disjunction and implication

## Preprocessing

In the preprocessing step we:

- use the supplied model to encode instances of model variables as MODELVAR(X) and formula FMLPTR (X) pointers as to make sure they are not matched with operators that are substrings as well as not stemmed
- we perform stemming on the imput sentence as well as each of the tokens in our grammar

Stemming is a NLP process that normalises tokens by transforming words into their gramatical stems to allow matching of the resulting stem with a host of possible words that mean the same thing eg: "eventual" and "eventually" can all be mapped by the stem "eventu"

## Lexing

In the lexing process we remove all the redundance tokens that do not exist in our grammar. For example in the input sentence: "show me a simulation where z=1 and k=2", the lexer would remove the tokens: "show me a simulation where". This process also separates strings of tokens into sets of tokens eg: "z=1" => ["z","=","1"]

## Parsing

The parser consumes the token stream generated by the lexer and procesesses it, generating an AST (Abstract Syntact Tree) which is a tree representation of the input sentence. The Chevotain library works using an implicit grammar approach where a set of "rules" are required to be specefied and based on the order of the rules, the grammar productions and operator precedence is infered.

More information on the API of the library can be found here: https://github.com/SAP/chevrotain/blob/master/docs/tutorial/step2_parsing.md 

### Error recovery

We use resynching as an error recovery mechanism in this parser, which works as follows:

- When an invalid token is encountered in the token stream, Chevrotain examines the rest of the token stream to detect any sets of tokens that match valid productions in our grammar
- If such a token set exists than Chevrotain returns this set which can be used in further parses

We use this feature in Chevrotain in the handleResynchedTokens() function to continually concatonate suffixes of resynched tokens (if more than one error exist) to generate a mutated input sentence that does not contain any invlaid tokens and also matches a valid production in the grammar, allowing us to handle the errors and parse the input successfully

Example:

- "no that and previous one were incorrect show me a simulation where it is always the case that if x is 1 then y is 5 and the whole thing is followed by z is 25"

In this scenario the lexed token stream will be:

- "and is always if x is 1 then y is 5 and  is followed by z is 25"

The first error token will then be "and" which will cause the following resynched tokens to be generated:

- "always if x is 1 then y is 5 and is followed by z is 25" (notice how the "is" was also skipped since there will never be a production that will match a sentence beginning with "is" as it is transalted to "=" in our grammar)

The second error token will be "is" in "and is followed by" which is not allowed by the grammar since it is translated to "and = next", this will cause the following resynched tokens to be generated:

- "always if x is 1 then y is 5 and followed by z is 25"

The result is then a valid sentence, that can be parsed using our grammar making the parser more resilient when dealing with complex natural language queries

## Postprocessing

The postprocessing step consists of parsing the generated AST into a sentence that can be returned to the user. This is currently done in ./NLParser/ASTUtils.ts by traversing the AST. ./NLParser/ASTUtils.ts Also handles inlining of formula pointers.